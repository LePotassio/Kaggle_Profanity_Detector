# -*- coding: utf-8 -*-
"""Copy of ML_Sem_Proj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    Redacted

# ***Toxic Comment Classifier***
### **Semester Team Project**, WSU CptS 437(Machine Learning), Spring 2021

First Name | Last Name | Student ID#
--- | --- | ---
Hien | Duong
Eric | Furukawa
Keuntae (Kurtis) | Kim

---
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
import csv

from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import cross_val_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.utils.class_weight import compute_sample_weight
from nltk.tokenize import TreebankWordTokenizer
from sklearn.feature_extraction import text
from sklearn.metrics import accuracy_score, f1_score
import numpy as np
import random
import pandas as pd

## Reference for naive bayes implementation
## https://geoffruddock.com/naive-bayes-from-scratch-with-numpy/

### Naive Bayes Implementation Functions ###

class NaiveBayes(object):
    def __init__(self, alpha=1.0):
        self.prior = None
        self.counts = None
        self.likelihood = None
        self.alpha = alpha

    def fit(self, X, y):
        n = X.shape[0]
        classes = []
        classes = np.array([X[y == i] for i in np.unique(y)])
        self.prior = np.array([len(c) / n for c in classes])
        self.counts = np.array([c.sum(axis=0) for c in classes]) + self.alpha
        self.likelihood = self.counts / self.counts.sum(axis=1).reshape(-1, 1)
        return self

    def predict(self, X):
        class_numerators = np.zeros(shape=(X.shape[0], self.prior.shape[0]))
        for i, x in enumerate(X):
            word_exists = x.astype(bool)
            lk_words_present = self.likelihood[:, word_exists] ** x[word_exists]
            lk_message = (lk_words_present).prod(axis=1)
            class_numerators[i] = lk_message * self.prior
        normalize_term = class_numerators.sum(axis=1).reshape(-1, 1)
        conditional_probas = class_numerators / normalize_term
        return conditional_probas.argmax(axis=1)

### /Naive Bayes Implementation Functions End ###

### Functions Start ###

def read_train_data():
    infile = open('/content/gdrive/My Drive/ML/SemProj/train.csv')

    category = infile.readline()    # exclude the first line(category) from the training data
    csv_reader = csv.reader(infile)

    #initialize lists
    # ids = []
    comments = []
    toxics = []
    severe_toxics = []
    obscenes = []
    threats = []
    insults = []
    identity_hates = []
    labels = []   # if any of them(toxics-identity hates) are true(1), then put labels 'toxic' or 'clean'

    for comment_info in csv_reader:
        # ids.append(comment_info[0])             # each comment info's [0] is the id
        comments.append(comment_info[1])        # each comment info's [1] is the comment text
        toxics.append(comment_info[2])          # each comment info's [2] is indicating whether it's toxic
        severe_toxics.append(comment_info[3])   # each comment info's [3] is indicating whether it's severely toxic
        obscenes.append(comment_info[4])        # each comment info's [4] is indicating whether it's obscene
        threats.append(comment_info[5])         # each comment info's [5] is indicating whether it has some threats
        insults.append(comment_info[6])         # each comment info's [6] is indicating whether it has insults
        identity_hates.append(comment_info[7])  # each comment info's [7] is indicating whether it's identity hate

    for comment in range(len(comments)):
        if int(toxics[comment]) == 1 or int(severe_toxics[comment]) == 1 or int(obscenes[comment]) == 1 \
        or int(threats[comment]) == 1 or int(insults[comment]) == 1 or int(identity_hates[comment]) == 1:
            labels.append('toxic')
        else:
            labels.append('clean')

        # train_data, train_y, toxic, severe_toxic, obscene, threats, insults, identity hate
    return comments, labels, toxics, severe_toxics, obscenes, threats, insults, identity_hates

def read_test_data():
    infile = open('/content/gdrive/My Drive/ML/SemProj/test.csv')
    inlabel = open('/content/gdrive/My Drive/ML/SemProj/test_labels.csv')

    category = infile.readline()    # exclude the first line(category) from the testing data
    csv_reader = csv.reader(infile)

    categoryL = inlabel.readline()  # exclude the first line(category) from the test label data
    csv_readerL = csv.reader(inlabel)

    #initialize lists
    # ids = []
    comments = []
    toxics = []
    severe_toxics = []
    obscenes = []
    threats = []
    insults = []
    identity_hates = []
    labels = [] # Ground truth

    for comment_info in csv_reader:
        # ids.append(comment_info[0])         # each comment info's [0] is the id
        comments.append(comment_info[1])    # each comment info's [1] is the comment text

    for comment_labels in csv_readerL:
        # ids.append(comment_labels[0])
        toxics.append(comment_labels[1])          # each comment info's [1] is indicating whether it's toxic
        severe_toxics.append(comment_labels[2])   # each comment info's [2] is indicating whether it's severely toxic
        obscenes.append(comment_labels[3])        # each comment info's [3] is indicating whether it's obscene
        threats.append(comment_labels[4])         # each comment info's [4] is indicating whether it has some threats
        insults.append(comment_labels[5])         # each comment info's [5] is indicating whether it has insults
        identity_hates.append(comment_labels[6])  # each comment info's [6] is indicating whether it's identity hate
        if int(comment_labels[1]) == 1 or int(comment_labels[2]) == 1 or int(comment_labels[3]) == 1 \
        or int(comment_labels[4]) == 1 or int(comment_labels[5]) == 1 or int(comment_labels[6]) == 1:
            labels.append('toxic')
        elif int(comment_labels[1]) == 0 or int(comment_labels[2]) == 0 or int(comment_labels[3]) == 0 \
        or int(comment_labels[4]) == 0 or int(comment_labels[5]) == 0 or int(comment_labels[6]) == 0:
            labels.append('clean')
        else:   # if it is '-1', then
                # not used for scoring
            labels.append('not_used')

        # test_data, test_y, toxic, severe_toxic, obscene, threats, insults, identity hate
    return comments, labels, toxics, severe_toxics, obscenes, threats, insults, identity_hates

def change_dataset_size(dataset, size):
    """
    'dataset' must be for X or y datasets
    'size' must be a percentage format in decimal point (e.g. 0.33)
    """
    dataset = dataset[:int((len(dataset)*size))]
    return dataset

def update_categories(y_test):
    updatedLabels = []

    # updating y_test
    for label_result in y_test:
        if label_result == "1" or label_result == "0":
            updatedLabels.append(label_result)
        else:       # if label_result == "-1", then do nothing
            continue
    
    return updatedLabels

def get_last_dups_index(y, name_dups):  # name_dups = name of duplicated item
    last_dups_index = 0

    for i in range(len(y)-1, -1, -1):   # e.g. find the last "toxic"'s index in y_dataset
        if y[i] == name_dups:           # e.g. "toxic"
            last_dups_index = i
            break
        else:
            continue

    return last_dups_index

def under_sampling(X, y, comp1, comp2):     # should be number of comp1 < number of comp2
    balanced_X = []       # initialize the balanced X_dataset list
    balanced_y = []       # initialize the balanced y_dataset list

    last_dup_index = get_last_dups_index(y, comp1)

    for i in range(len(y)):
        if i > last_dup_index:    # There are no more "comp1"s in y_dataset after this index number.
            if balanced_y.count(comp1) < balanced_y.count(comp2):
                # need to trim "comp2" items
                for j in range(len(balanced_y[:])-1, -1, -1):     # remove "comp2"s from backward in balanced_y_dataset.
                    if balanced_y.count(comp1) < balanced_y.count(comp2):
                        if balanced_y[j] == comp2:
                            del balanced_X[j]
                            del balanced_y[j]
                    elif balanced_y.count(comp1) == balanced_y.count(comp2):
                        # done trimming
                        break
                    else:
                        print(f"ERROR: It can't be {comp1} > {comp2}!")
                        break
            elif balanced_y.count(comp1) > balanced_y.count(comp2):
                for j in range(len(balanced_y[:])-1, -1, -1):     # remove "comp2"s from backward in balanced_y_dataset.
                    if balanced_y.count(comp1) > balanced_y.count(comp2):
                        if balanced_y[j] == comp1:
                            del balanced_X[j]
                            del balanced_y[j]
                    elif balanced_y.count(comp1) == balanced_y.count(comp2):
                        # done trimming
                        break
                    else:
                        print(f"ERROR: It can't be {comp1} < {comp2}!")
                        break
            else:       # balanced_y_train.count(comp1) == balanced_y_train.count(comp2)
                break   # if they are the same amount, then break out the for loop
        else:     # i <= last_dup_index
            balanced_X.append(X[i])
            balanced_y.append(y[i])
    
    return balanced_X, balanced_y

def learn(X_train, y_train, X_test, y_test, weights):
    newy_train = []
    newy_test = []
    
    for i in range(len(y_train)):
        if y_train[i] == "clean" or y_train[i] == "0":
            newy_train.append("0")
        elif y_train[i] == "toxic" or y_train[i] == "1":
            newy_train.append("1")
    y_train = newy_train
    for i in range(len(y_test)):
        if y_test[i] == "clean" or y_test[i] == "0":
            newy_test.append("0")
        elif y_test[i] == "toxic" or y_test[i] == "1":
            newy_test.append("1")
    y_test = newy_test

    # train a naive Bayes classifier on data
    # X_train is a sparse matrix of word counts remember!
    clf = MultinomialNB().fit(X_train, y_train, sample_weight=weights)
    #What do we predict on? They must have the same dimensionality arrays
    predictedLabelsTrain = clf.predict(X_train)
    predictedLabels = clf.predict(X_test)
    
    # Using our own NaiveBayes Classifier
    clf2 = NaiveBayes().fit(np.array(X_train.toarray()), np.array(y_train))
    NBLabels = clf2.predict(np.array(X_train.toarray()))
    NBLabels_test = clf2.predict(np.array(X_test.toarray()))

    predictedNBLabels = []
    for x in NBLabels:
        if x == 0:
            predictedNBLabels.append("0")
        else:
            predictedNBLabels.append("1")
    predictedNBLabels_Test = []
    for y in NBLabels_test:
        if y == 0:
            predictedNBLabels_Test.append("0")
        else:
            predictedNBLabels_Test.append("1")

    correctT = 0
    incorrectT = 0
    nbcT = 0
    inbcT = 0
    for i in range(len(predictedLabelsTrain)):
        if predictedLabelsTrain[i] == y_train[i]:
            correctT += 1
        else:
            incorrectT += 1
    for i in range(len(predictedNBLabels)):
        if predictedNBLabels[i] == y_train[i]:
            nbcT += 1
        else:
            inbcT += 1
    print("-"*12, "Training dataset", "-"*13)
    print('Accuracy score:\t\t', correctT/(correctT + incorrectT))
    # print('Accuracy score:\t', accuracy_score(y_train, predictedLabelsTrain))
    print('f1-macro score:\t\t', f1_score(y_train, predictedLabelsTrain, average='macro'))
    print("-"*43)
    print('Our NB Accuracy score:\t', nbcT/(nbcT + inbcT))
    # print('Accuracy score:\t', accuracy_score(y_train, predictedLabelsTrain))
    print('Our NB f1-macro score:\t', f1_score(y_train, predictedNBLabels, average='macro'))
    print("-"*43)

    correct = 0
    incorrect = 0
    nbc = 0
    inbc = 0
    for i in range(len(predictedLabels)):
        if predictedLabels[i] == y_test[i]:
            correct += 1
        else:
            incorrect += 1
    for i in range(len(predictedNBLabels_Test)):
        if predictedNBLabels_Test[i] == y_test[i]:
            nbc += 1
        else:
            inbc += 1
    print("-"*13, "Testing dataset", "-"*13)
    print('Accuracy score:\t\t', correct/(correct + incorrect))
    # print('Accuracy score:\t', accuracy_score(y_test, predictedLabels))
    print('f1-macro score:\t\t', f1_score(y_test, predictedLabels, average='macro'))
    print("-"*43)
    print('Our NB Accuracy score:\t', nbc/(nbc + inbc))
    # print('Accuracy score:\t', accuracy_score(y_test, predictedLabels))
    print('Our NB f1-macro score:\t', f1_score(y_test, predictedNBLabels_Test, average='macro'))
    print("-"*43)

def sklearn_NBC(X_train, X_test, y_train, y_test):
    count_vect = CountVectorizer(stop_words = set(text.ENGLISH_STOP_WORDS))
    tokenizer = TreebankWordTokenizer()
    count_vect.set_params(tokenizer=tokenizer.tokenize)

    count_vect.set_params(ngram_range=(1,2))        # include 1-grams and 2-grams

    count_vect.set_params(max_df=0.5)               # ignore terms that appear in >50% of the documents
    count_vect.set_params(min_df=2)                 # ignore terms that appear in only 1 document

    X_counts = count_vect.fit_transform(X_train)    # transform text to bag of words vector using parameters

    X_test_counts = count_vect.transform(X_test)

    # normalize counts based on document length
    # weight common words less (is, a, an, the)
    tfidf_transformer = TfidfTransformer()
    X_tfidf = tfidf_transformer.fit_transform(X_counts)
    X_test_tfidf = tfidf_transformer.transform(X_test_counts)

    weights = np.full(len(y_train), 1.0, dtype=float)
    learn(X_tfidf, y_train, X_test_tfidf, y_test, weights)

    print()

### Main Start ###

if __name__ == "__main__":
    print("******************************")
    print("***** Code Project Begin *****")
    print("******************************\n")

    X_train, y_train, toxics_train, severe_toxics_train, obscenes_train, threats_train, insults_train, identity_hates_train = read_train_data()
    X_test, y_test, toxics_test, severe_toxics_test, obscenes_test, threats_test, insults_test, identity_hates_test = read_test_data()

    # change the datasets size
    X_train = change_dataset_size(X_train, 0.33)
    y_train = change_dataset_size(y_train, 0.33)
    toxics_train = change_dataset_size(toxics_train, 0.33)
    severe_toxics_train = change_dataset_size(severe_toxics_train, 0.33)
    obscenes_train = change_dataset_size(obscenes_train, 0.33)
    threats_train = change_dataset_size(threats_train, 0.33)
    insults_train = change_dataset_size(insults_train, 0.33)
    identity_hates_train = change_dataset_size(identity_hates_train, 0.33)
    X_test = change_dataset_size(X_test, 0.33)
    y_test = change_dataset_size(y_test, 0.33)
    toxics_test = change_dataset_size(toxics_test, 0.33)
    severe_toxics_test = change_dataset_size(severe_toxics_test, 0.33)
    obscenes_test = change_dataset_size(obscenes_test, 0.33)
    threats_test = change_dataset_size(threats_test, 0.33)
    insults_test = change_dataset_size(insults_test, 0.33)
    identity_hates_test = change_dataset_size(identity_hates_test, 0.33)

    updated_X_test = []         # initialize updated X_test list excluding corresponding to y_test's indices.
    updated_y_test = []         # initialize updated y_test list excluding 'not_used's
    # updating X_test
    for i in range(len(y_test)):
        if y_test[i] == "toxic" or y_test[i] == "clean":
            updated_X_test.append(X_test[i])
        else:                   # if y_test[i] == "not_used", then do nothing
            continue
    # updating y_test
    for label_result in y_test:
        if label_result == "toxic" or label_result == "clean":
            updated_y_test.append(label_result)
        else:                   # if label_result == "not_used", then do nothing
            continue

    # For improving class imbalance for TRAINING dataset
    if y_train.count("toxic") < y_train.count("clean"):
        # Undersampling
        balanced_X_train_U1, balanced_y_train_U1 = under_sampling(X_train, y_train, "toxic", "clean")
        balanced_X_train_U2, balanced_toxics_train_U2 = under_sampling(X_train, toxics_train, "1", "0")
        balanced_X_train_U3, balanced_severe_toxics_train_U3 = under_sampling(X_train, severe_toxics_train, "1", "0")
        balanced_X_train_U4, balanced_obscenes_train_U4 = under_sampling(X_train, obscenes_train, "1", "0")
        balanced_X_train_U5, balanced_threats_train_U5 = under_sampling(X_train, threats_train, "1", "0")
        balanced_X_train_U6, balanced_insults_train_U6 = under_sampling(X_train, insults_train, "1", "0")
        balanced_X_train_U7, balanced_identity_hates_train_U7 = under_sampling(X_train, identity_hates_train, "1", "0")
    else:       # if y_train.count("toxic") == y_train.count("clean"), then no sampling
        print("SYSTEM: Training dataset is already balanced.")

    # For improving class imbalance for TESTING dataset
    if updated_y_test.count("toxic") < updated_y_test.count("clean"):
        # Undersampling
        balanced_X_test_U1, balanced_y_test_U1 = under_sampling(updated_X_test, updated_y_test, "toxic", "clean")
        balanced_X_test_U2, balanced_toxics_test_U2 = under_sampling(updated_X_test, update_categories(toxics_test), "1", "0")
        balanced_X_test_U3, balanced_severe_toxics_test_U3 = under_sampling(updated_X_test, update_categories(severe_toxics_test), "1", "0")
        balanced_X_test_U4, balanced_obscenes_test_U4 = under_sampling(updated_X_test, update_categories(obscenes_test), "1", "0")
        balanced_X_test_U5, balanced_threats_test_U5 = under_sampling(updated_X_test, update_categories(threats_test), "1", "0")
        balanced_X_test_U6, balanced_insults_test_U6 = under_sampling(updated_X_test, update_categories(insults_test), "1", "0")
        balanced_X_test_U7, balanced_identity_hates_test_U7 = under_sampling(updated_X_test, update_categories(identity_hates_test), "1", "0")
    elif updated_y_test.count("toxic") > updated_y_test.count("clean"):
        # Undersampling
        balanced_X_test_U1, balanced_y_test_U1 = under_sampling(updated_X_test, updated_y_test, "clean", "toxic")
        balanced_X_test_U2, balanced_toxics_test_U2 = under_sampling(updated_X_test, update_categories(toxics_test), "0", "1")
        balanced_X_test_U3, balanced_severe_toxics_test_U3 = under_sampling(updated_X_test, update_categories(severe_toxics_test), "0", "1")
        balanced_X_test_U4, balanced_obscenes_test_U4 = under_sampling(updated_X_test, update_categories(obscenes_test), "0", "1")
        balanced_X_test_U5, balanced_threats_test_U5 = under_sampling(updated_X_test, update_categories(threats_test), "0", "1")
        balanced_X_test_U6, balanced_insults_test_U6 = under_sampling(updated_X_test, update_categories(insults_test), "0", "1")
        balanced_X_test_U7, balanced_identity_hates_test_U7 = under_sampling(updated_X_test, update_categories(identity_hates_test), "0", "1")
    else:       # if updated_y_test.count("toxic") == updated_y_test.count("clean"), then no sampling
        print("SYSTEM: Testing dataset is already balanced.")

    # now use updated X_test and y_test
    #sklearn_NBC(X_train, updated_X_test, y_train, updated_y_test)

    # now use balanced datasets
    sklearn_NBC(balanced_X_train_U1, balanced_X_test_U1, balanced_y_train_U1, balanced_y_test_U1)

    ### Toxics
    print("\n***** Toxics *****")
    sklearn_NBC(balanced_X_train_U2, balanced_X_test_U2, balanced_toxics_train_U2, balanced_toxics_test_U2)

    ### Severe Toxics
    print("\n***** Severe Toxics *****")
    sklearn_NBC(balanced_X_train_U3, balanced_X_test_U3, balanced_severe_toxics_train_U3, balanced_severe_toxics_test_U3)

    ### Obscenes
    print("\n***** Obscenes *****")
    sklearn_NBC(balanced_X_train_U4, balanced_X_test_U4, balanced_obscenes_train_U4, balanced_obscenes_test_U4)

    ### Threats
    print("\n***** Threats *****")
    sklearn_NBC(balanced_X_train_U5, balanced_X_test_U5, balanced_threats_train_U5, balanced_threats_test_U5)

    ### Insults
    print("\n***** Insults *****")
    sklearn_NBC(balanced_X_train_U6, balanced_X_test_U6, balanced_insults_train_U6, balanced_insults_test_U6)

    # Identity Hates
    print("\n***** Identity Hates *****")
    sklearn_NBC(balanced_X_train_U7, balanced_X_test_U7, balanced_identity_hates_train_U7, balanced_identity_hates_test_U7)

### /Main End ###